{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772825df",
   "metadata": {
    "papermill": {
     "duration": 0.034298,
     "end_time": "2024-01-30T01:55:35.328886",
     "exception": false,
     "start_time": "2024-01-30T01:55:35.294588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://www.kaggle.com/code/rkuo2000/chromadb-langchain-gpt4all\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/gpt4all\n",
    "\n",
    "https://github.com/nomic-ai/gpt4all/tree/main/gpt4all-bindings/python\n",
    "\n",
    "https://www.kaggle.com/code/gpreda/test-gpt4all-on-kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1941323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:55:35.399183Z",
     "iopub.status.busy": "2024-01-30T01:55:35.398859Z",
     "iopub.status.idle": "2024-01-30T01:55:35.408348Z",
     "shell.execute_reply": "2024-01-30T01:55:35.407610Z"
    },
    "papermill": {
     "duration": 0.047407,
     "end_time": "2024-01-30T01:55:35.410271",
     "exception": false,
     "start_time": "2024-01-30T01:55:35.362864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0a6f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:55:35.480293Z",
     "iopub.status.busy": "2024-01-30T01:55:35.479624Z",
     "iopub.status.idle": "2024-01-30T01:55:36.496795Z",
     "shell.execute_reply": "2024-01-30T01:55:36.495715Z"
    },
    "papermill": {
     "duration": 1.055591,
     "end_time": "2024-01-30T01:55:36.499007",
     "exception": false,
     "start_time": "2024-01-30T01:55:35.443416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-104c8356-6afb-2580-0024-8f3db933580a)\r\n",
      "GPU 1: Tesla T4 (UUID: GPU-7b6c8258-d60e-95a8-0afc-bbb7514d4d2c)\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bace2b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:55:36.569163Z",
     "iopub.status.busy": "2024-01-30T01:55:36.568804Z",
     "iopub.status.idle": "2024-01-30T01:57:34.467403Z",
     "shell.execute_reply": "2024-01-30T01:57:34.466266Z"
    },
    "papermill": {
     "duration": 117.969528,
     "end_time": "2024-01-30T01:57:34.503065",
     "exception": false,
     "start_time": "2024-01-30T01:55:36.533537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
      "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\r\n",
      "google-cloud-pubsublite 1.8.3 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.7.0 which is incompatible.\r\n",
      "jupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.0.1 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp 1.19.0 requires opentelemetry-exporter-otlp-proto-grpc==1.19.0, but you have opentelemetry-exporter-otlp-proto-grpc 1.22.0 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp-proto-http 1.19.0 requires opentelemetry-exporter-otlp-proto-common==1.19.0, but you have opentelemetry-exporter-otlp-proto-common 1.22.0 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp-proto-http 1.19.0 requires opentelemetry-proto==1.19.0, but you have opentelemetry-proto 1.22.0 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp-proto-http 1.19.0 requires opentelemetry-sdk~=1.19.0, but you have opentelemetry-sdk 1.22.0 which is incompatible.\r\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCPU times: user 1.3 s, sys: 350 ms, total: 1.65 s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! pip install -qq -U langchain tiktoken pypdf chromadb faiss-gpu\n",
    "! pip install -qq -U transformers InstructorEmbedding sentence_transformers\n",
    "! pip install -qq -U bitsandbytes bitsandbytes-cuda117\n",
    "! pip install -qq -U gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32798dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:57:34.616266Z",
     "iopub.status.busy": "2024-01-30T01:57:34.615914Z",
     "iopub.status.idle": "2024-01-30T01:57:34.620272Z",
     "shell.execute_reply": "2024-01-30T01:57:34.619448Z"
    },
    "papermill": {
     "duration": 0.085233,
     "end_time": "2024-01-30T01:57:34.622166",
     "exception": false,
     "start_time": "2024-01-30T01:57:34.536933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d8ce07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:57:34.690911Z",
     "iopub.status.busy": "2024-01-30T01:57:34.690584Z",
     "iopub.status.idle": "2024-01-30T01:57:55.524531Z",
     "shell.execute_reply": "2024-01-30T01:57:55.523493Z"
    },
    "papermill": {
     "duration": 20.871023,
     "end_time": "2024-01-30T01:57:55.526698",
     "exception": false,
     "start_time": "2024-01-30T01:57:34.655675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.4\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import textwrap\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import langchain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n",
    "\n",
    "#quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)\n",
    "\n",
    "#os.environ['TRANSFORMERS_CACHE'] = 'cache/'\n",
    "\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f2af6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:57:55.598534Z",
     "iopub.status.busy": "2024-01-30T01:57:55.597989Z",
     "iopub.status.idle": "2024-01-30T01:57:58.503873Z",
     "shell.execute_reply": "2024-01-30T01:57:58.502908Z"
    },
    "papermill": {
     "duration": 2.944359,
     "end_time": "2024-01-30T01:57:58.506317",
     "exception": false,
     "start_time": "2024-01-30T01:57:55.561958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Multi-document retriever\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import RetrievalQA, VectorDBQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "#from gpt4all import GPT4All\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed8f881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:57:58.576225Z",
     "iopub.status.busy": "2024-01-30T01:57:58.575145Z",
     "iopub.status.idle": "2024-01-30T02:05:53.360545Z",
     "shell.execute_reply": "2024-01-30T02:05:53.359443Z"
    },
    "papermill": {
     "duration": 474.822036,
     "end_time": "2024-01-30T02:05:53.362705",
     "exception": false,
     "start_time": "2024-01-30T01:57:58.540669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-30 01:57:59--  https://gpt4all.io/models/gguf/mistral-7b-openorca.Q4_0.gguf\r\n",
      "Resolving gpt4all.io (gpt4all.io)... 172.67.71.169, 104.26.1.159, 104.26.0.159, ...\r\n",
      "Connecting to gpt4all.io (gpt4all.io)|172.67.71.169|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 4108927744 (3.8G)\r\n",
      "Saving to: 'mistral-7b-openorca.Q4_0.gguf'\r\n",
      "\r\n",
      "mistral-7b-openorca 100%[===================>]   3.83G  7.67MB/s    in 7m 53s  \r\n",
      "\r\n",
      "2024-01-30 02:05:53 (8.28 MB/s) - 'mistral-7b-openorca.Q4_0.gguf' saved [4108927744/4108927744]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://gpt4all.io/models/gguf/mistral-7b-openorca.Q4_0.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e83dc6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T02:05:53.785544Z",
     "iopub.status.busy": "2024-01-30T02:05:53.785207Z",
     "iopub.status.idle": "2024-01-30T02:05:56.247798Z",
     "shell.execute_reply": "2024-01-30T02:05:56.247006Z"
    },
    "papermill": {
     "duration": 2.675581,
     "end_time": "2024-01-30T02:05:56.250147",
     "exception": false,
     "start_time": "2024-01-30T02:05:53.574566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "llm = GPT4All(model=\"/kaggle/working/mistral-7b-openorca.Q4_0.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba356eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T02:05:56.675805Z",
     "iopub.status.busy": "2024-01-30T02:05:56.675096Z",
     "iopub.status.idle": "2024-01-30T02:05:56.679312Z",
     "shell.execute_reply": "2024-01-30T02:05:56.678397Z"
    },
    "papermill": {
     "duration": 0.214406,
     "end_time": "2024-01-30T02:05:56.681410",
     "exception": false,
     "start_time": "2024-01-30T02:05:56.467004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(llm.generate(\"The capital of France is \", max_tokens=1028))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b267f640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T02:05:57.164164Z",
     "iopub.status.busy": "2024-01-30T02:05:57.163817Z",
     "iopub.status.idle": "2024-01-30T02:05:57.171030Z",
     "shell.execute_reply": "2024-01-30T02:05:57.170189Z"
    },
    "papermill": {
     "duration": 0.264105,
     "end_time": "2024-01-30T02:05:57.172983",
     "exception": false,
     "start_time": "2024-01-30T02:05:56.908878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT4All(model='/kaggle/working/mistral-7b-openorca.Q4_0.gguf', client=<gpt4all.gpt4all.GPT4All object at 0x7dae2028fdf0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883b756b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T02:05:57.605266Z",
     "iopub.status.busy": "2024-01-30T02:05:57.604910Z",
     "iopub.status.idle": "2024-01-30T02:13:15.765768Z",
     "shell.execute_reply": "2024-01-30T02:13:15.764712Z"
    },
    "papermill": {
     "duration": 438.594286,
     "end_time": "2024-01-30T02:13:15.982987",
     "exception": false,
     "start_time": "2024-01-30T02:05:57.388701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/mk-vectordb-chroma'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree('/kaggle/input/mkvc-6-finalmix/kaggle/working/mk-vectordb-chroma-six', '/kaggle/working/mk-vectordb-chroma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85263c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T02:13:16.431076Z",
     "iopub.status.busy": "2024-01-30T02:13:16.430312Z",
     "iopub.status.idle": "2024-01-30T02:13:17.959851Z",
     "shell.execute_reply": "2024-01-30T02:13:17.958966Z"
    },
    "papermill": {
     "duration": 1.763509,
     "end_time": "2024-01-30T02:13:17.961861",
     "exception": false,
     "start_time": "2024-01-30T02:13:16.198352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d38fbefd444056ae7e7fb06ea5401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:149\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mInstructorEmbedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INSTRUCTOR\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mINSTRUCTOR\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDependencies for InstructorEmbedding not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:194\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, trust_remote_code, revision, token, use_auth_token)\u001b[0m\n\u001b[1;32m    191\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(model_name_or_path, token, cache_folder\u001b[38;5;241m=\u001b[39mcache_folder, revision\u001b[38;5;241m=\u001b[39mrevision):\n\u001b[0;32m--> 194\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[1;32m    203\u001b[0m         model_name_or_path,\n\u001b[1;32m    204\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m    208\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"intfloat/multilingual-e5-base\", model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "vectordb = Chroma(persist_directory='mk-vectordb-chroma',embedding_function=instructor_embeddings,)\n",
    "#vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36722c8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T02:13:18.399029Z",
     "iopub.status.busy": "2024-01-30T02:13:18.398584Z",
     "iopub.status.idle": "2024-01-30T02:13:18.436735Z",
     "shell.execute_reply": "2024-01-30T02:13:18.435977Z"
    },
    "papermill": {
     "duration": 0.259114,
     "end_time": "2024-01-30T02:13:18.438642",
     "exception": false,
     "start_time": "2024-01-30T02:13:18.179528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectordb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectordb' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "#retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6, \"lambda_mult\": 0.25})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                       chain_type=\"stuff\", \n",
    "                                       retriever=retriever, \n",
    "                                       return_source_documents=True,\n",
    "                                       verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4a071d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T02:13:18.874998Z",
     "iopub.status.busy": "2024-01-30T02:13:18.874213Z",
     "iopub.status.idle": "2024-01-30T02:13:19.074504Z",
     "shell.execute_reply": "2024-01-30T02:13:19.073158Z"
    },
    "papermill": {
     "duration": 0.419986,
     "end_time": "2024-01-30T02:13:19.076252",
     "exception": true,
     "start_time": "2024-01-30T02:13:18.656266",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mqa_chain\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qa_chain' is not defined"
     ]
    }
   ],
   "source": [
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec77ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T16:05:16.149075Z",
     "iopub.status.busy": "2024-01-08T16:05:16.148735Z",
     "iopub.status.idle": "2024-01-08T16:05:16.154959Z",
     "shell.execute_reply": "2024-01-08T16:05:16.154141Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c28117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T16:05:16.246168Z",
     "iopub.status.busy": "2024-01-08T16:05:16.245827Z",
     "iopub.status.idle": "2024-01-08T16:05:16.250340Z",
     "shell.execute_reply": "2024-01-08T16:05:16.249420Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm_ans(query):\n",
    "    llm_response = qa_chain(query)\n",
    "    ans = process_llm_response(llm_response)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eaac3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T16:05:16.346249Z",
     "iopub.status.busy": "2024-01-08T16:05:16.345597Z",
     "iopub.status.idle": "2024-01-08T16:05:16.349632Z",
     "shell.execute_reply": "2024-01-08T16:05:16.348938Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fcd63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T16:05:16.444508Z",
     "iopub.status.busy": "2024-01-08T16:05:16.443761Z",
     "iopub.status.idle": "2024-01-08T16:05:16.509526Z",
     "shell.execute_reply": "2024-01-08T16:05:16.508621Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/kaggle/input/mkri-qa-3/dataset.csv',sep=';')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737975d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T16:05:16.614847Z",
     "iopub.status.busy": "2024-01-08T16:05:16.614523Z",
     "iopub.status.idle": "2024-01-08T18:38:49.128296Z",
     "shell.execute_reply": "2024-01-08T18:38:49.127220Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for x,y in zip(dataset.no,dataset.qa_comb):\n",
    "    llm_time_start = time.time()\n",
    "    print(\"Nomor: \",x)\n",
    "    print(y)\n",
    "    llm_ans(y)\n",
    "    llm_time_end = time.time()\n",
    "    print(\"Time: \",llm_time_end - llm_time_start)\n",
    "    print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ff9b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:38:49.303253Z",
     "iopub.status.busy": "2024-01-08T18:38:49.302904Z",
     "iopub.status.idle": "2024-01-08T18:38:49.308093Z",
     "shell.execute_reply": "2024-01-08T18:38:49.307042Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3946908,
     "sourceId": 6867748,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3809209,
     "sourceId": 6602260,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1071.217072,
   "end_time": "2024-01-30T02:13:22.838558",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-30T01:55:31.621486",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2f6cf4a5c15146f5947e8d19ea7f69c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae6565fae34147dfa8b2b16a9985a27f",
       "placeholder": "​",
       "style": "IPY_MODEL_a161ed9c3ad1440e9489f4c5cefa7c7c",
       "value": "modules.json: 100%"
      }
     },
     "2fdf870e0dae430694b197b36510e11d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83b3672593d04aa8bd92664794e02201": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8651c923a9a54a13bff81d1c6cd46d1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d52a04526e004a74825df6b6e6f68ea3",
       "placeholder": "​",
       "style": "IPY_MODEL_b28ddf32043a4a15ae41f4d2143c6336",
       "value": " 387/387 [00:00&lt;00:00, 28.4kB/s]"
      }
     },
     "a161ed9c3ad1440e9489f4c5cefa7c7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ae6565fae34147dfa8b2b16a9985a27f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b28ddf32043a4a15ae41f4d2143c6336": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c52242e93b064e9e99ff768032899b41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0d38fbefd444056ae7e7fb06ea5401e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2f6cf4a5c15146f5947e8d19ea7f69c1",
        "IPY_MODEL_fc50bdbe968248969132dccc83919e36",
        "IPY_MODEL_8651c923a9a54a13bff81d1c6cd46d1d"
       ],
       "layout": "IPY_MODEL_c52242e93b064e9e99ff768032899b41"
      }
     },
     "d52a04526e004a74825df6b6e6f68ea3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc50bdbe968248969132dccc83919e36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2fdf870e0dae430694b197b36510e11d",
       "max": 387.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83b3672593d04aa8bd92664794e02201",
       "value": 387.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
