{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd90002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T10:13:35.692081Z",
     "iopub.status.busy": "2024-01-13T10:13:35.691199Z",
     "iopub.status.idle": "2024-01-13T10:13:35.701046Z",
     "shell.execute_reply": "2024-01-13T10:13:35.700240Z"
    },
    "papermill": {
     "duration": 0.019666,
     "end_time": "2024-01-13T10:13:35.702900",
     "exception": false,
     "start_time": "2024-01-13T10:13:35.683234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990b0ce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T10:13:35.715624Z",
     "iopub.status.busy": "2024-01-13T10:13:35.715287Z",
     "iopub.status.idle": "2024-01-13T10:17:13.938610Z",
     "shell.execute_reply": "2024-01-13T10:17:13.937750Z"
    },
    "papermill": {
     "duration": 218.232258,
     "end_time": "2024-01-13T10:17:13.941022",
     "exception": false,
     "start_time": "2024-01-13T10:13:35.708764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic==1.10.8\r\n",
      "  Downloading pydantic-1.10.8.tar.gz (345 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.3/345.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.8) (4.6.3)\r\n",
      "Building wheels for collected packages: pydantic\r\n",
      "  Building wheel for pydantic (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pydantic: filename=pydantic-1.10.8-cp310-cp310-linux_x86_64.whl size=3144054 sha256=a3d484cbd4358c982d2ae9709f15e7110feb2c841eeadb302b2ce42456c018c6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d4/4e/e1/fe50ebef30316809195d0dfeb3097792383a648f9dbb171f4d\r\n",
      "Successfully built pydantic\r\n",
      "Installing collected packages: pydantic\r\n",
      "  Attempting uninstall: pydantic\r\n",
      "    Found existing installation: pydantic 1.10.9\r\n",
      "    Uninstalling pydantic-1.10.9:\r\n",
      "      Successfully uninstalled pydantic-1.10.9\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pydantic-1.10.8\r\n",
      "Collecting openai\r\n",
      "  Downloading openai-1.7.2-py3-none-any.whl (212 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (3.7.0)\r\n",
      "Collecting distro<2,>=1.7.0 (from openai)\r\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\r\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.10.8)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\r\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\r\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.1.1)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\r\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\r\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Installing collected packages: typing-extensions, httpcore, distro, httpx, openai\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.6.3\r\n",
      "    Uninstalling typing_extensions-4.6.3:\r\n",
      "      Successfully uninstalled typing_extensions-4.6.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "chex 0.1.82 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\r\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\r\n",
      "ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed distro-1.9.0 httpcore-1.0.2 httpx-0.26.0 openai-1.7.2 typing-extensions-4.6.3\r\n"
     ]
    }
   ],
   "source": [
    "! pip install --no-binary :all: pydantic==1.10.8\n",
    "! pip install openai\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbee0e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T10:17:13.958646Z",
     "iopub.status.busy": "2024-01-13T10:17:13.957748Z",
     "iopub.status.idle": "2024-01-13T10:17:58.144805Z",
     "shell.execute_reply": "2024-01-13T10:17:58.143682Z"
    },
    "papermill": {
     "duration": 44.204802,
     "end_time": "2024-01-13T10:17:58.153789",
     "exception": false,
     "start_time": "2024-01-13T10:17:13.948987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/typing_extensions-4.6.3.dist-info/METADATA'\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/typing_extensions-4.6.3.dist-info/METADATA'\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCPU times: user 698 ms, sys: 152 ms, total: 851 ms\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! pip install -qq -U langchain tiktoken pypdf chromadb faiss-gpu\n",
    "! pip install -qq -U transformers InstructorEmbedding sentence_transformers\n",
    "! pip install -qq -U bitsandbytes bitsandbytes-cuda117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708518e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T10:17:58.172055Z",
     "iopub.status.busy": "2024-01-13T10:17:58.171673Z",
     "iopub.status.idle": "2024-01-13T10:17:59.325588Z",
     "shell.execute_reply": "2024-01-13T10:17:59.324083Z"
    },
    "papermill": {
     "duration": 1.165191,
     "end_time": "2024-01-13T10:17:59.327210",
     "exception": true,
     "start_time": "2024-01-13T10:17:58.162019",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline, OpenAI\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import textwrap\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import langchain\n",
    "from langchain.llms import HuggingFacePipeline, OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n",
    "\n",
    "#quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)\n",
    "\n",
    "#os.environ['TRANSFORMERS_CACHE'] = 'cache/'\n",
    "\n",
    "print(langchain.__version__)\n",
    "\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfc8ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:53:59.671699Z",
     "iopub.status.busy": "2023-12-14T03:53:59.671413Z",
     "iopub.status.idle": "2023-12-14T03:53:59.676233Z",
     "shell.execute_reply": "2023-12-14T03:53:59.675163Z",
     "shell.execute_reply.started": "2023-12-14T03:53:59.671673Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_secrets = UserSecretsClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2a812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:53:59.678603Z",
     "iopub.status.busy": "2023-12-14T03:53:59.677792Z",
     "iopub.status.idle": "2023-12-14T03:54:02.489201Z",
     "shell.execute_reply": "2023-12-14T03:54:02.488208Z",
     "shell.execute_reply.started": "2023-12-14T03:53:59.678568Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Multi-document retriever\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import RetrievalQA, VectorDBQA, LLMChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25183133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:54:02.491365Z",
     "iopub.status.busy": "2023-12-14T03:54:02.490447Z",
     "iopub.status.idle": "2023-12-14T03:54:02.496236Z",
     "shell.execute_reply": "2023-12-14T03:54:02.495260Z",
     "shell.execute_reply.started": "2023-12-14T03:54:02.491336Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e0da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:31:40.806756Z",
     "iopub.status.busy": "2023-12-14T04:31:40.805589Z",
     "iopub.status.idle": "2023-12-14T04:31:41.313861Z",
     "shell.execute_reply": "2023-12-14T04:31:41.312807Z",
     "shell.execute_reply.started": "2023-12-14T04:31:40.806717Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = llm = OpenAI(openai_api_key=user_secrets.get_secret(\"openai_key\"),model=\"gpt-3.5-turbo\",openai_organization=user_secrets.get_secret(\"open_org\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163de98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:22:42.366104Z",
     "iopub.status.busy": "2023-12-14T04:22:42.365747Z",
     "iopub.status.idle": "2023-12-14T04:22:42.372971Z",
     "shell.execute_reply": "2023-12-14T04:22:42.371962Z",
     "shell.execute_reply.started": "2023-12-14T04:22:42.366079Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0481ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:54:02.831963Z",
     "iopub.status.busy": "2023-12-14T03:54:02.831618Z",
     "iopub.status.idle": "2023-12-14T03:56:04.925165Z",
     "shell.execute_reply": "2023-12-14T03:56:04.924114Z",
     "shell.execute_reply.started": "2023-12-14T03:54:02.831933Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.copytree('/kaggle/input/mkvc-9-finalmix/kaggle/working/mk-vectordb-chroma-nine', '/kaggle/working/mk-vectordb-chroma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac908d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:56:04.926721Z",
     "iopub.status.busy": "2023-12-14T03:56:04.926446Z",
     "iopub.status.idle": "2023-12-14T03:56:29.611290Z",
     "shell.execute_reply": "2023-12-14T03:56:29.610331Z",
     "shell.execute_reply.started": "2023-12-14T03:56:04.926698Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"LazarusNLP/simcse-indobert-base\", model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "vectordb = Chroma(persist_directory='mk-vectordb-chroma',embedding_function=instructor_embeddings,)\n",
    "#vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4b07c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:56:29.613080Z",
     "iopub.status.busy": "2023-12-14T03:56:29.612703Z",
     "iopub.status.idle": "2023-12-14T03:56:29.620839Z",
     "shell.execute_reply": "2023-12-14T03:56:29.619809Z",
     "shell.execute_reply.started": "2023-12-14T03:56:29.613044Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3, \"search_type\" : \"similarity\"})\n",
    "#retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6, \"lambda_mult\": 0.25})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                       chain_type=\"stuff\", \n",
    "                                       retriever=retriever, \n",
    "                                       return_source_documents=True,\n",
    "                                       verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b4710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:56:29.623084Z",
     "iopub.status.busy": "2023-12-14T03:56:29.622207Z",
     "iopub.status.idle": "2023-12-14T03:56:29.640402Z",
     "shell.execute_reply": "2023-12-14T03:56:29.639417Z",
     "shell.execute_reply.started": "2023-12-14T03:56:29.623016Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eae45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:56:29.641807Z",
     "iopub.status.busy": "2023-12-14T03:56:29.641545Z",
     "iopub.status.idle": "2023-12-14T03:56:29.650374Z",
     "shell.execute_reply": "2023-12-14T03:56:29.649524Z",
     "shell.execute_reply.started": "2023-12-14T03:56:29.641784Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacfc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T03:56:29.651669Z",
     "iopub.status.busy": "2023-12-14T03:56:29.651427Z",
     "iopub.status.idle": "2023-12-14T03:56:29.660489Z",
     "shell.execute_reply": "2023-12-14T03:56:29.659697Z",
     "shell.execute_reply.started": "2023-12-14T03:56:29.651647Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm_ans(query):\n",
    "    llm_response = qa_chain(query)\n",
    "    ans = process_llm_response(llm_response)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d9009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:10:15.676911Z",
     "iopub.status.busy": "2023-12-14T04:10:15.676509Z",
     "iopub.status.idle": "2023-12-14T04:10:15.681486Z",
     "shell.execute_reply": "2023-12-14T04:10:15.680464Z",
     "shell.execute_reply.started": "2023-12-14T04:10:15.676880Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d2f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:10:15.684154Z",
     "iopub.status.busy": "2023-12-14T04:10:15.683577Z",
     "iopub.status.idle": "2023-12-14T04:10:15.758502Z",
     "shell.execute_reply": "2023-12-14T04:10:15.757470Z",
     "shell.execute_reply.started": "2023-12-14T04:10:15.684117Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/kaggle/input/mkri-qa-3/dataset.csv',sep=';')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b45dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:33:56.812767Z",
     "iopub.status.busy": "2023-12-14T04:33:56.811823Z",
     "iopub.status.idle": "2023-12-14T04:34:00.429610Z",
     "shell.execute_reply": "2023-12-14T04:34:00.428494Z",
     "shell.execute_reply.started": "2023-12-14T04:33:56.812731Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for x,y in zip(dataset.no,dataset.qa_comb):\n",
    "    llm_time_start = time.time()\n",
    "    print(\"Nomor: \",x)\n",
    "    print(y)\n",
    "    llm_ans(y)\n",
    "    llm_time_end = time.time()\n",
    "    print(\"Time: \",llm_time_end - llm_time_start)\n",
    "    print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743af1f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:10:41.540336Z",
     "iopub.status.busy": "2023-12-14T04:10:41.539953Z",
     "iopub.status.idle": "2023-12-14T04:10:41.545423Z",
     "shell.execute_reply": "2023-12-14T04:10:41.544442Z",
     "shell.execute_reply.started": "2023-12-14T04:10:41.540300Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3813772,
     "sourceId": 6609450,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3947022,
     "sourceId": 6868021,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 267.744123,
   "end_time": "2024-01-13T10:17:59.956192",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-13T10:13:32.212069",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
